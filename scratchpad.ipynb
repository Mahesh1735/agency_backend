{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from typing import Annotated, TypedDict\n",
    "\n",
    "class linkedin_post_generator(TypedDict):\n",
    "    \"\"\"\n",
    "    Generate a LinkedIn post\n",
    "    \"\"\"\n",
    "    linkedin_page_url: Annotated[str, 'https://www.linkedin.com/in/mahesh-kumar-a90000200/', \"linkedin_page_url\"]\n",
    "    post_content: Annotated[str, 'hello world', \"post_content\"]\n",
    "    target_audience: Annotated[str, 'software engineers', \"target_audience\"]\n",
    "\n",
    "class short_form_video_generator(TypedDict):\n",
    "    \"\"\"\n",
    "    Generate a short form video\n",
    "    \"\"\"\n",
    "    topic: Annotated[str, ..., \"topic\"]\n",
    "    hook: Annotated[str, ..., \"hook\"]\n",
    "    target_audience: Annotated[str, ..., \"target_audience\"]\n",
    "    tiktok_page_url: Annotated[str, ..., \"tiktok_page_url\"]\n",
    "\n",
    "tools = {\"linkedin_post_generator\": linkedin_post_generator, \"short_form_video_generator\": short_form_video_generator}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = linkedin_post_generator()linkedin_page_url=\"https://www.linkedin.com/in/mahesh-kumar-a90000200/\", post_content=\"hello world\", target_audience=\"software engineers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'linkedin_page_url': 'https://www.linkedin.com/in/mahesh-kumar-a90000200/',\n",
       " 'post_content': 'hello world',\n",
       " 'target_audience': 'software engineers'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.linkedin_post_generator"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linkedin_post_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[__main__.linkedin_post_generator, __main__.short_form_video_generator]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from IPython.display import Image\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from agent import Agent\n",
    "\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4o-mini\", openai_api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "abot = Agent(model, tools, memory)\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "res = abot.graph.invoke({\"messages\": [HumanMessage(content=\"What is the weather in sf?\")]}, config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [('human', 'What is the weather in sf?'),\n",
       "  AIMessage(content=\"I'm unable to provide real-time weather updates. However, you can easily check the current weather in San Francisco by using a weather website or app. If you have any other questions or need assistance with something else, feel free to ask!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 48, 'prompt_tokens': 206, 'total_tokens': 254, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bba3c8e70b', 'finish_reason': 'stop', 'logprobs': None}, id='run-ee51ea54-58be-4c8e-a197-68c4a4037f8e-0', usage_metadata={'input_tokens': 206, 'output_tokens': 48, 'total_tokens': 254, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
       " 'generations': []}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(abot.graph.get_graph().draw_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hi', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Hello! How can I assist you today? Are you looking for help with generating a LinkedIn post or a short form video?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 200, 'total_tokens': 227, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bba3c8e70b', 'finish_reason': 'stop', 'logprobs': None}, id='run-d6264361-3225-49d1-853a-0d7419f26572-0', usage_metadata={'input_tokens': 200, 'output_tokens': 27, 'total_tokens': 227, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
       " 'generations': []}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"343\"}}\n",
    "res = abot.graph.invoke({\"messages\": [HumanMessage(content=\"Hi\")]}, config)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hi', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Hello! How can I assist you today? Are you looking for help with generating a LinkedIn post or a short form video?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 200, 'total_tokens': 227, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bba3c8e70b', 'finish_reason': 'stop', 'logprobs': None}, id='run-d6264361-3225-49d1-853a-0d7419f26572-0', usage_metadata={'input_tokens': 200, 'output_tokens': 27, 'total_tokens': 227, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  HumanMessage(content='I want to generate a LinkedIn post', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Great! To help you generate a LinkedIn post, I'll need a bit more information:\\n\\n1. What is the URL of your LinkedIn page?\\n2. What content would you like to include in the post?\\n3. Who is your target audience for this post?\\n\\nOnce I have this information, I can create the post for you!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 69, 'prompt_tokens': 242, 'total_tokens': 311, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bba3c8e70b', 'finish_reason': 'stop', 'logprobs': None}, id='run-2da41073-1295-4554-a5fb-1a7c5df9dc7b-0', usage_metadata={'input_tokens': 242, 'output_tokens': 69, 'total_tokens': 311, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
       " 'generations': []}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = abot.graph.invoke({\"messages\": [HumanMessage(content=\"I want to generate a LinkedIn post\")]}, config)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hi', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Hello! How can I assist you today? Are you looking for help with generating a LinkedIn post or a short form video?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 200, 'total_tokens': 227, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bba3c8e70b', 'finish_reason': 'stop', 'logprobs': None}, id='run-d6264361-3225-49d1-853a-0d7419f26572-0', usage_metadata={'input_tokens': 200, 'output_tokens': 27, 'total_tokens': 227, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  HumanMessage(content='I want to generate a LinkedIn post', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Great! To help you generate a LinkedIn post, I'll need a bit more information:\\n\\n1. What is the URL of your LinkedIn page?\\n2. What content would you like to include in the post?\\n3. Who is your target audience for this post?\\n\\nOnce I have this information, I can create the post for you!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 69, 'prompt_tokens': 242, 'total_tokens': 311, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bba3c8e70b', 'finish_reason': 'stop', 'logprobs': None}, id='run-2da41073-1295-4554-a5fb-1a7c5df9dc7b-0', usage_metadata={'input_tokens': 242, 'output_tokens': 69, 'total_tokens': 311, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  HumanMessage(content='My LinkedIn page url is https://www.linkedin.com/in/mahesh-kumar-a90000200/', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Thank you for providing your LinkedIn page URL! Now, could you please share the content you would like to include in the post? Additionally, who is your target audience for this post?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 340, 'total_tokens': 379, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bba3c8e70b', 'finish_reason': 'stop', 'logprobs': None}, id='run-38d9792a-cd6e-4645-8c3e-9c5ea1f13651-0', usage_metadata={'input_tokens': 340, 'output_tokens': 39, 'total_tokens': 379, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
       " 'generations': []}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = abot.graph.invoke({\"messages\": [HumanMessage(content=\"My LinkedIn page url is https://www.linkedin.com/in/mahesh-kumar-a90000200/\")]}, config)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hi', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Hello! How can I assist you today? Are you looking for help with generating a LinkedIn post or a short form video?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 200, 'total_tokens': 227, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bba3c8e70b', 'finish_reason': 'stop', 'logprobs': None}, id='run-d6264361-3225-49d1-853a-0d7419f26572-0', usage_metadata={'input_tokens': 200, 'output_tokens': 27, 'total_tokens': 227, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  HumanMessage(content='I want to generate a LinkedIn post', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Great! To help you generate a LinkedIn post, I'll need a bit more information:\\n\\n1. What is the URL of your LinkedIn page?\\n2. What content would you like to include in the post?\\n3. Who is your target audience for this post?\\n\\nOnce I have this information, I can create the post for you!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 69, 'prompt_tokens': 242, 'total_tokens': 311, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bba3c8e70b', 'finish_reason': 'stop', 'logprobs': None}, id='run-2da41073-1295-4554-a5fb-1a7c5df9dc7b-0', usage_metadata={'input_tokens': 242, 'output_tokens': 69, 'total_tokens': 311, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  HumanMessage(content='My LinkedIn page url is https://www.linkedin.com/in/mahesh-kumar-a90000200/', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Thank you for providing your LinkedIn page URL! Now, could you please share the content you would like to include in the post? Additionally, who is your target audience for this post?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 340, 'total_tokens': 379, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bba3c8e70b', 'finish_reason': 'stop', 'logprobs': None}, id='run-38d9792a-cd6e-4645-8c3e-9c5ea1f13651-0', usage_metadata={'input_tokens': 340, 'output_tokens': 39, 'total_tokens': 379, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  HumanMessage(content=\"My post content is 'hello world'\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Got it! Now, could you please specify your target audience for this post? For example, are you targeting professionals in a specific industry, job seekers, entrepreneurs, etc.?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 394, 'total_tokens': 430, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bba3c8e70b', 'finish_reason': 'stop', 'logprobs': None}, id='run-b9829d09-5add-4f80-82d6-7fb953ceca4a-0', usage_metadata={'input_tokens': 394, 'output_tokens': 36, 'total_tokens': 430, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
       " 'generations': []}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = abot.graph.invoke({\"messages\": [HumanMessage(content=\"My post content is 'hello world'\")]}, config)\n",
    "res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hi', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Hello! How can I assist you today? Are you looking for help with generating a LinkedIn post or a short form video?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 200, 'total_tokens': 227, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bba3c8e70b', 'finish_reason': 'stop', 'logprobs': None}, id='run-d6264361-3225-49d1-853a-0d7419f26572-0', usage_metadata={'input_tokens': 200, 'output_tokens': 27, 'total_tokens': 227, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  HumanMessage(content='I want to generate a LinkedIn post', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Great! To help you generate a LinkedIn post, I'll need a bit more information:\\n\\n1. What is the URL of your LinkedIn page?\\n2. What content would you like to include in the post?\\n3. Who is your target audience for this post?\\n\\nOnce I have this information, I can create the post for you!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 69, 'prompt_tokens': 242, 'total_tokens': 311, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bba3c8e70b', 'finish_reason': 'stop', 'logprobs': None}, id='run-2da41073-1295-4554-a5fb-1a7c5df9dc7b-0', usage_metadata={'input_tokens': 242, 'output_tokens': 69, 'total_tokens': 311, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  HumanMessage(content='My LinkedIn page url is https://www.linkedin.com/in/mahesh-kumar-a90000200/', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Thank you for providing your LinkedIn page URL! Now, could you please share the content you would like to include in the post? Additionally, who is your target audience for this post?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 340, 'total_tokens': 379, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bba3c8e70b', 'finish_reason': 'stop', 'logprobs': None}, id='run-38d9792a-cd6e-4645-8c3e-9c5ea1f13651-0', usage_metadata={'input_tokens': 340, 'output_tokens': 39, 'total_tokens': 379, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  HumanMessage(content=\"My post content is 'hello world'\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Got it! Now, could you please specify your target audience for this post? For example, are you targeting professionals in a specific industry, job seekers, entrepreneurs, etc.?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 394, 'total_tokens': 430, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bba3c8e70b', 'finish_reason': 'stop', 'logprobs': None}, id='run-b9829d09-5add-4f80-82d6-7fb953ceca4a-0', usage_metadata={'input_tokens': 394, 'output_tokens': 36, 'total_tokens': 430, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  HumanMessage(content='My target audience is software engineers', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Thank you for the information! Here’s a summary of what I have for your LinkedIn post:\\n\\n- **LinkedIn Page URL:** [https://www.linkedin.com/in/mahesh-kumar-a90000200/](https://www.linkedin.com/in/mahesh-kumar-a90000200/)\\n- **Post Content:** \"hello world\"\\n- **Target Audience:** Software Engineers\\n\\nNow, I will generate the LinkedIn post for you. One moment, please!', additional_kwargs={'tool_calls': [{'id': 'call_m2VDIkmMxhzKoB7Sj5yh1H9h', 'function': {'arguments': '{\"linkedin_page_url\":\"https://www.linkedin.com/in/mahesh-kumar-a90000200/\",\"post_content\":\"hello world\",\"target_audience\":\"Software Engineers\"}', 'name': 'linkedin_post_generator'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 141, 'prompt_tokens': 443, 'total_tokens': 584, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bba3c8e70b', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-c2ba1848-38f5-473f-87cb-1b2bdc0f8b12-0', tool_calls=[{'name': 'linkedin_post_generator', 'args': {'linkedin_page_url': 'https://www.linkedin.com/in/mahesh-kumar-a90000200/', 'post_content': 'hello world', 'target_audience': 'Software Engineers'}, 'id': 'call_m2VDIkmMxhzKoB7Sj5yh1H9h', 'type': 'tool_call'}], usage_metadata={'input_tokens': 443, 'output_tokens': 141, 'total_tokens': 584, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
       " 'generations': []}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = abot.graph.invoke({\"messages\": [HumanMessage(content=\"My target audience is software engineers\")]}, config)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. The following tool_call_ids did not have response messages: call_m2VDIkmMxhzKoB7Sj5yh1H9h\", 'type': 'invalid_request_error', 'param': 'messages.[11].role', 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mabot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGenerate the post\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m res\n",
      "File \u001b[0;32m~/hanu_ai/agency/backend/venv_agency/lib/python3.10/site-packages/langgraph/pregel/__init__.py:1929\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   1927\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1928\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1929\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[1;32m   1930\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   1931\u001b[0m     config,\n\u001b[1;32m   1932\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39mstream_mode,\n\u001b[1;32m   1933\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[1;32m   1934\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[1;32m   1935\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[1;32m   1936\u001b[0m     debug\u001b[38;5;241m=\u001b[39mdebug,\n\u001b[1;32m   1937\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1938\u001b[0m ):\n\u001b[1;32m   1939\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1940\u001b[0m         latest \u001b[38;5;241m=\u001b[39m chunk\n",
      "File \u001b[0;32m~/hanu_ai/agency/backend/venv_agency/lib/python3.10/site-packages/langgraph/pregel/__init__.py:1649\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1643\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[1;32m   1644\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[1;32m   1645\u001b[0m     \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[1;32m   1646\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[1;32m   1648\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[0;32m-> 1649\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[1;32m   1650\u001b[0m             loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m   1651\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[1;32m   1652\u001b[0m             retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[1;32m   1653\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[1;32m   1654\u001b[0m         ):\n\u001b[1;32m   1655\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[1;32m   1657\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[0;32m~/hanu_ai/agency/backend/venv_agency/lib/python3.10/site-packages/langgraph/pregel/runner.py:105\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    103\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/hanu_ai/agency/backend/venv_agency/lib/python3.10/site-packages/langgraph/pregel/retry.py:44\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, writer)\u001b[0m\n\u001b[1;32m     42\u001b[0m task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/hanu_ai/agency/backend/venv_agency/lib/python3.10/site-packages/langgraph/utils/runnable.py:410\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    408\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 410\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/hanu_ai/agency/backend/venv_agency/lib/python3.10/site-packages/langgraph/utils/runnable.py:184\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    183\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m--> 184\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/hanu_ai/agency/backend/agent.py:61\u001b[0m, in \u001b[0;36mAgent.orchestrator\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     58\u001b[0m messages \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     59\u001b[0m messages \u001b[38;5;241m=\u001b[39m [SystemMessage(content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morchestrator_system_prompt)] \u001b[38;5;241m+\u001b[39m messages\n\u001b[0;32m---> 61\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m'\u001b[39m: [response]}\n",
      "File \u001b[0;32m~/hanu_ai/agency/backend/venv_agency/lib/python3.10/site-packages/langchain_core/runnables/base.py:5354\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m   5349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5350\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[1;32m   5351\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   5352\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   5353\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[0;32m-> 5354\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5355\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5356\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5357\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5358\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/hanu_ai/agency/backend/venv_agency/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:286\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    282\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    283\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    285\u001b[0m         ChatGeneration,\n\u001b[0;32m--> 286\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    296\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/hanu_ai/agency/backend/venv_agency/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:786\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    780\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    784\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    785\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/hanu_ai/agency/backend/venv_agency/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:643\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[1;32m    642\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 643\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    644\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    645\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[1;32m    646\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m    647\u001b[0m ]\n\u001b[1;32m    648\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[0;32m~/hanu_ai/agency/backend/venv_agency/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:633\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 633\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    639\u001b[0m         )\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/hanu_ai/agency/backend/venv_agency/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:851\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    850\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 851\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    855\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/hanu_ai/agency/backend/venv_agency/lib/python3.10/site-packages/langchain_openai/chat_models/base.py:689\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m     generation_info \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response\u001b[38;5;241m.\u001b[39mheaders)}\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 689\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response, generation_info)\n",
      "File \u001b[0;32m~/hanu_ai/agency/backend/venv_agency/lib/python3.10/site-packages/openai/_utils/_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/hanu_ai/agency/backend/venv_agency/lib/python3.10/site-packages/openai/resources/chat/completions.py:829\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    826\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    827\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    828\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/hanu_ai/agency/backend/venv_agency/lib/python3.10/site-packages/openai/_base_client.py:1280\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1267\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1268\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1275\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1276\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1277\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1278\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1279\u001b[0m     )\n\u001b[0;32m-> 1280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/hanu_ai/agency/backend/venv_agency/lib/python3.10/site-packages/openai/_base_client.py:957\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    955\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 957\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/hanu_ai/agency/backend/venv_agency/lib/python3.10/site-packages/openai/_base_client.py:1061\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1058\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1060\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1061\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1064\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1065\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1070\u001b[0m )\n",
      "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. The following tool_call_ids did not have response messages: call_m2VDIkmMxhzKoB7Sj5yh1H9h\", 'type': 'invalid_request_error', 'param': 'messages.[11].role', 'code': None}}"
     ]
    }
   ],
   "source": [
    "res = abot.graph.invoke({\"messages\": [HumanMessage(content=\"Generate the post\")]}, config)\n",
    "res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hi', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Hello! How can I assist you today? Are you looking for help with generating a LinkedIn post or creating a short form video?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 200, 'total_tokens': 228, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bba3c8e70b', 'finish_reason': 'stop', 'logprobs': None}, id='run-49542cf8-79a4-444b-956f-12c9b52b6bd0-0', usage_metadata={'input_tokens': 200, 'output_tokens': 28, 'total_tokens': 228, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
       " 'generations': []}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1231\"}}\n",
    "res = abot.graph.invoke({\"messages\": [HumanMessage(content=\"Hi\")]}, config)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hi', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Hello! How can I assist you today? Are you looking for help with generating a LinkedIn post or creating a short form video?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 200, 'total_tokens': 228, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bba3c8e70b', 'finish_reason': 'stop', 'logprobs': None}, id='run-49542cf8-79a4-444b-956f-12c9b52b6bd0-0', usage_metadata={'input_tokens': 200, 'output_tokens': 28, 'total_tokens': 228, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  HumanMessage(content='I want to generate a short form video', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Great! I can help you with that. Could you please provide me with the following details?\\n\\n1. **Topic**: What is the subject or theme of the video?\\n2. **Hook**: What engaging opening statement or question would you like to use to grab attention?\\n3. **Target Audience**: Who are you trying to reach with this video?\\n4. **TikTok Page URL**: If you have a TikTok page, please provide the URL. \\n\\nOnce I have this information, I can generate the short form video for you!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 113, 'prompt_tokens': 243, 'total_tokens': 356, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bba3c8e70b', 'finish_reason': 'stop', 'logprobs': None}, id='run-72279f4d-57d2-4c58-b934-f0b38db42955-0', usage_metadata={'input_tokens': 243, 'output_tokens': 113, 'total_tokens': 356, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
       " 'generations': []}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = abot.graph.invoke({\"messages\": [HumanMessage(content=\"I want to generate a short form video\")]}, config)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_agency",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
